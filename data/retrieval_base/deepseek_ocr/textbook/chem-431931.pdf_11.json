[
  {
    "page_idx": 0,
    "text": "\\[ RSD = 100 \\times \\frac{\\sigma}{\\bar{x}} \\]  \n\n(4)\n\nConfidence Interval\n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, \\(\\bar{x}\\). The confidence interval is given by:\n\n\\[ \\mu = \\bar{x} \\pm \\frac{t\\sigma}{\\sqrt{n}} \\]  \n\n(5)\n\nwhere \\(\\mu\\) is the interval, and \\(t\\) is the students \\(t\\), which can be looked up in the student's table (available in many textbooks or online). The value of \\(t\\) for a 95% confidence interval can be found in Table 1:\n\n| degrees of freedom (n - 1) | 95% Confidence Interval \\(t\\) Value |\n|-----------------------------|--------------------------------|\n| 1                           | 12.706                            |\n| 2                           | 4.303                            |\n| 3                           | 3.182                            |\n| 4                           | 2.776                            |\n| 5                           | 2.571                            |\n| 6                           | 2.447                            |\n| 7                           | 2.365                            |\n| 8                           | 2.306                            |\n| 9                           | 2.262                            |\n| 10                          | 2.228                            |\n| 15                         | 2.131                            |\n| 20                         | 2.086                            |\n| 25                         | 2.060                            |\n| 30                         | 2.042                            |\n| 40                         | 2.021                            |\n| 60                         | 2.000                            |\n| 120                        | 1.980                            |\n| âˆž                          | 1.960                            |\n\n(6)\n\nDiscarding Data\n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.\n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For \\(3 \\leq n \\leq 10\\), where \\(n\\) is the number of measurements of the same quantity, calculate:\n\n\\[ Q = \\frac{\\text{isuspect value} - \\text{value closest to it}}{\\text{highest value} - \\text{lowest value}} \\]  \n\n(7)\n\nCompare the value of \\(Q\\) with \\(Q_c\\) from Table 2. If \\(Q > Q_c\\), you can reject the suspect value."
  }
]